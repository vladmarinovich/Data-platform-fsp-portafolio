# üèóÔ∏è Arquitectura de Datos: SPDP (Salvando Patitas Data Platform)

Este documento describe la arquitectura t√©cnica de nuestra plataforma, dise√±ada bajo el paradigma **Lakehouse**. La soluci√≥n integra un robusto ingestion pipeline en Python con un potente motor de transformaci√≥n en Dataform (Google Cloud).

---

## üèõÔ∏è Dise√±o Conceptual: Medallion Architecture

Hemos implementado una arquitectura de tres capas ("Medallion") para garantizar la calidad y gobernanza de los datos en cada etapa del proceso.


![Arquitectura Detallada SPDP](img/Flujo%20Pipeline.jpeg)


### ü•â Bronze Layer (Raw)
*   **Fuente:** API transaccional de Supabase.
*   **Formato:** Archivos Parquet nativos con tipado estricto.
*   **Estrategia:** Ingesta incremental diaria (basada en `last_modified_at`) + Snapshots totales para cat√°logos maestros.
*   **Objetivo:** Ser la "fuente de la verdad" inmutable. Si algo falla aguas abajo, siempre podemos reconstruir desde aqu√≠.

### ü•à Silver Layer (Clean & Trusted)
*   **Herramienta:** Dataform (SQLX).
*   **Transformaciones:**
    *   **Deduplicaci√≥n:** Uso de `ROW_NUMBER() OVER(PARTITION BY id ORDER BY last_modified_at DESC)` para obtener la √∫ltima versi√≥n de cada registro.
    *   **Limpieza de Tipos:** Casteo seguro (`SAFE_CAST`) de strings a timestamps/numerics, tratamiento de nulos (`COALESCE`).
    *   **Integridad:** Validaciones b√°sicas de claves for√°neas.
*   **Objetivo:** Tener datos limpios y listos para consultar, eliminando basura t√©cnica.
    
    ![Silver Layer Logic](img/dataform-modelo-logico%20de-transformacioÃÅn-y-calidad-de-datos-silver-layer.jpg)

### ü•á Gold Layer (Business Ready)
*   **Modelo:** Esquema Estrella (Star Schema) modificado.
    
    *Modelo Dimensional (Dimensions):*
    ![Gold Dimensions](img/gold-layer-dimensional-model-dims.jpg)
    
    *Modelo de Hechos (Facts):*
    ![Gold Facts](img/gold-fact-tables-modelo-analitico-de-hechos.jpg)
    *   **Dimensions (DIM):** `dim_casos`, `dim_donantes`, `dim_proveedores`, `dim_hogar`. Tablas desnormalizadas con atributos descriptivos.
    *   **Facts (FACT):** `facts_donaciones`, `facts_gastos`. Tablas transaccionales enriquecidas con claves sustitutas.
    *   **Features (FEAT):** `feat_donaciones`, `feat_gastos`. Ingenier√≠a de caracter√≠sticas espec√≠fica para alimentar modelos de Machine Learning (aggregations, rolling windows, RFM scoring).
    
    ![Feature Store](img/feat-layer-feature-store-analitico-ml-y-scoring.jpg)

---

## üîÑ Pipeline de Extracci√≥n (Python)

El coraz√≥n de la ingesta es un script modular optimizado para latencia y costo.

### 1. Tablas Transaccionales (Estrategia Incremental)
*   **Scope:** `casos`, `donaciones`, `gastos`, `donantes`.
*   **L√≥gica:** Consulta solo registros donde `updated_at > watermark_anterior`.
*   **Persistencia:** Particionamiento Hive (`y=YYYY/m=MM/d=DD`) en GCS para optimizar costos de query en BigQuery.

### 2. Tablas Maestras (Estrategia Snapshot)
*   **Scope:** `proveedores`, `hogar_de_paso`.
*   **L√≥gica:** Descarga completa (`Full Refresh`) en cada ejecuci√≥n.
*   **Persistencia:** Sobrescritura en ruta `latest/` para garantizar unicidad sin l√≥gica compleja de deduplicaci√≥n.

### üöÄ CI/CD & Despliegue
Flujo automatizado de construcci√≥n y publicaci√≥n del artefacto Docker:

![Deployment Flow](img/deployment-flow-CI-CD-build-y-publish.jpeg)

---

## üß™ Calidad de Datos (Data Quality Assurance)

No confiamos ciegamente en los datos. Hemos implementado un framework de pruebas automatizadas con **Dataform Assertions**:

1.  **Unicidad:** `assert_unique_key` valida que no existan IDs duplicados en capa Silver.
2.  **Referencialidad:** Validamos que cada `id_donante` en donaciones exista en la tabla de `donantes`.
3.  **Reglas de Negocio:**
    *   Montos de donaci√≥n no pueden ser negativos.
    *   Fechas de pago no pueden ser futuras (a m√°s de 1 d√≠a) ni anteriores a 2010.

Si una aserci√≥n falla, el pipeline alerta al equipo, pero (configurado actualmente) no detiene el flujo cr√≠tico, permitiendo an√°lisis post-mortem.

---
**Arquitecto:** Vladislav Marinovich  
**Stack:** GCP (BigQuery, GCS, Dataform), Python, Supabase.
