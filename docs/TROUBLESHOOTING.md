# üêõ Bit√°cora de Errores y Soluciones (Troubleshooting Log)
**Proyecto:** Salvando Patitas Data Platform (SPDP)  
**Componente:** Pipeline de Extracci√≥n (Supabase -> GCS -> BigQuery)  
**Fecha:** Diciembre 2025

Esta bit√°cora documenta los desaf√≠os t√©cnicos encontrados durante la implementaci√≥n del Data Lake, sus causas ra√≠z y las soluciones aplicadas. Sirve como base de conocimiento para mantenimiento futuro y entrevistas t√©cnicas.

---

## üìÖ Timeline de Desaf√≠os y Resoluciones

### 1. üîå El Bloqueo del Connection Pooler (PgBouncer)
**S√≠ntoma:** El script original usando `sqlalchemy`/`psycopg2` fallaba al conectar a Supabase, o se ca√≠a intermitentemente.
**Causa:** Supabase en modo transaccional (puerto 6543) y IPv4 en redes restringidas causaban timeouts y handshake errors.
**Soluci√≥n:**
*   Abandonar la conexi√≥n directa a base de datos (SQL).
*   Migrar al **Cliente Supabase Python (REST API)**. Esto desacopla la infraestructura de red, usa HTTPS est√°ndar (puerto 443) y es mucho m√°s resiliente.

### 2. üìù El Fantasma de los "string nan"
**S√≠ntoma:** En BigQuery, columnas que deber√≠an ser vac√≠as aparec√≠an con el texto literal `"nan"` o `"None"`.
**Causa:** Una regla de limpieza en Pandas convert√≠a *todo* objeto a string (`astype(str)`), transformando los valores nulos (`NaN`, `None`) en las cadenas de texto `"nan"`.
**Soluci√≥n:**
*   Agregar un paso de limpieza pos-conversi√≥n:
    ```python
    df[col] = df[col].replace({'nan': None, 'None': None, '<NA>': None})
    ```
*   Esto restaura el objeto `None` nativo, que Parquet y BigQuery interpretan correctamente como `NULL`.

### 3. üî• El Incidente de los N√∫meros Perdidos (Monto vs Texto)
**S√≠ntoma:** Columnas de texto importantes (ej. "descripci√≥n") aparec√≠an todas como `NULL`.
**Causa:** Una l√≥gica agresiva intentaba convertir cualquier columna con palabras como "valor" o "desc" a num√©rico (`to_numeric(errors='coerce')`). Al fallar la conversi√≥n de texto a n√∫mero, Pandas borraba el contenido.
**Soluci√≥n:**
*   Refinar las palabras clave de detecci√≥n (`money_keywords`).
*   Ser expl√≠citos: solo convertir a Float columnas como `monto`, `presupuesto`, `costo`.
*   Para todo lo dem√°s: Respetar el tipo original.

### 4. üßü‚Äç‚ôÇÔ∏è Archivos Zombies: "Type Mismatch" (Double vs Int64)
**S√≠ntoma:** Error en BigQuery al leer tablas externas (`raw_casos`, `raw_donaciones`, `raw_gastos`):
> `Parquet column 'id_hogar_de_paso' (o 'id_caso') has type DOUBLE which does not match the target cpp_type INT64.`
**Causa (Schema Drift):**
*   **Archivos Viejos:** Generados cuando Pandas infer√≠a IDs nulos como Float (`15.0`).
*   **Archivos Nuevos:** Generados con la nueva regla estricta `Int64` (`15`).
*   **Conflicto:** BigQuery no puede leer una carpeta mezclada.
**Soluci√≥n:**
*   **C√≥digo:** Implementar la regla estricta `astype('Int64')` para todas las columnas terminadas en `_id` y PKs expl√≠citas.
*   **Limpieza (The Nuclear Option):** Borrar f√≠sicamente el historial del bucket (`gsutil rm ...`) para eliminar los archivos con esquema viejo.
*   **Recarga (Backfill):** Reprocesar todo el historial con el nuevo c√≥digo estricto. Se aplic√≥ tabla por tabla (`casos`, `donaciones`, `gastos`).

### 5. üìõ Desalineaci√≥n de Nombres (Schema Mismatch)
**S√≠ntoma:** Columnas llenas de NULLs en BigQuery a pesar de tener datos en el Parquet.
**Causa:** La definici√≥n de la tabla externa en BigQuery esperaba nombres como `nombre_animal`, pero el Parquet ven√≠a de la fuente como `nombre_caso`. BigQuery, al no encontrar la columna exacta, rellenaba con NULL.
**Soluci√≥n:**
*   **Filosof√≠a ELT:** Aceptar que la capa Raw/Bronze debe ser un espejo de la fuente.
*   **Acci√≥n:** Ejecutar `CREATE OR REPLACE EXTERNAL TABLE` en BigQuery para que auto-detecte los nombres reales del Parquet.
*   **Validaci√≥n:** Se cre√≥ el script `scripts/test_transformation.py` para imprimir los nombres exactos de columnas y garantizar alineaci√≥n.

### 6. üßπ Limpieza de Datos Sensibles e Innecesarios
**Necesidad:** La tabla `donantes` conten√≠a campos pesados (`archivos`) y sensibles (`notas`).
**Soluci√≥n:**
*   Implementar una regla de exclusi√≥n temprana en el extractor:
    ```python
    if table_name == 'donantes':
        df = df.drop(columns=['notas', 'archivos'], errors='ignore')
    ```
*   Esto reduce costos de almacenamiento y riesgos de privacidad.

---

## üõ† Estado Final de la Arquitectura

1.  **Extractor:** Python Multithreaded (20 workers).
2.  **Validaci√≥n de Tipos:** Estricta (Fechas, Int64 IDs, Float Montos, String Textos).
3.  **Manejo de Nulos:** Nativo (NULL real).
4.  **Estrategia de Carga:**
    *   **Incremental:** `last_modified_at` (Insert + Update).
    *   **Deduplicaci√≥n:** Se delega a la capa Silver (SQL).
5.  **Formato:** Parquet con particionamiento Hive (`y=YYYY/m=MM/d=DD`).

---

### 7. üö® Alerta de Calidad de Datos (Pendiente)
**Incidente:** Dataform reporta fallo en la aserci√≥n `assert_silver_gastos`.
**S√≠ntoma:** Error `Assertion failed, expected zero rows`.
**Causa Probable:**
*   Existen registros en `silver_gastos` que violan integridad referencial (FK hacia Proveedores o Casos).
*   Posibles duplicados o montos negativos.
**Estado:** Deuda t√©cnica registrada. El pipeline contin√∫a su ejecuci√≥n (no bloqueante), pero se debe investigar y limpiar la data raw en Supabase.
**Acci√≥n Futura:**
1.  Ejecutar query de diagn√≥stico en BigQuery para identificar IDs culpables.
2.  Corregir datos en origen (Supabase) o ajustar regla de negocio.

